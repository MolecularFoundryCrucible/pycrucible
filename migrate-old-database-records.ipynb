{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 1,
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
   "id": "d8b2392d-443a-41e7-aa2a-8ad8d1cdf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "from pycrucible.pycrucible import *\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
=======
    "from pycrucible.pycrucible import *"
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "1bbed5c9-950a-457e-94e6-5408a0ecb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.environ.get('apikey')\n",
    "old_apikey = os.environ.get('old_apikey')"
=======
   "execution_count": 2,
   "id": "4e47360d-84de-48fa-b450-921f4a3c98f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb626b680a044dabc9d6e4b60f132f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Enter secret:</b>'), Password(placeholder='Enter secret here', style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apikey= SecureInput()"
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
   "id": "f74039c5-9c4b-4942-87be-de9da61c2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "crux = CrucibleClient(\"https://crucible.lbl.gov/testapi\", apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "29f0c17e-f16b-47f8-95ff-7ffde0041b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull all the dataset IDs from the old Crucible API (https://crucible.lbl.gov/api) using requests\n",
    "old_url = \"https://crucible.lbl.gov/api\"\n",
    "old_dsids = requests.get(f'{old_url}/list_datasets', headers = {\"Authorization\": f\"Bearer {old_apikey}\"}).json()\n",
    "old_dsids = [x['unique_id'] for x in old_dsids]\n",
    "new_ds = crux.list_datasets()\n",
    "new_dsids = [x['unique_id'] for x in new_ds]\n",
    "\n",
    "\n",
    "# for each dataset ID in the old database - check if it exists in the new database using the CrucibleClient\n",
    "missing_ds = [dsid for dsid in old_dsids if dsid not in new_dsids]\n",
    "print(len(missing_ds))\n",
    "with open('missing_ids.txt', 'w') as f:\n",
    "    f.writelines('\\n'.join(missing_ds))"
   ]
=======
   "id": "86bf30ef-897c-4f4f-9bee-c5fc1e485c8e",
   "metadata": {},
   "outputs": [],
   "source": "import requests\n\n# Pull all the dataset IDs from the old Crucible API\nold_api_url = \"https://crucible.lbl.gov/api\"\nresponse = requests.get(f\"{old_api_url}/datasets\")\nresponse.raise_for_status()\n\nold_datasets = response.json()\nold_dataset_ids = [dataset['id'] for dataset in old_datasets]\nprint(f\"Found {len(old_dataset_ids)} datasets in old database\")\nprint(f\"First 10 dataset IDs: {old_dataset_ids[:10]}\")"
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "efbc59bc-f941-460c-ae6e-7eb5b4b3ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('missing_ids.txt', 'r') as f:\n",
    "    missing_ds = [x.replace('\\n', '').strip() for x in f.readlines()]\n",
    "print(len(missing_ds))\n",
    "print(missing_ds[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b76c1-5a1d-400a-872c-52f1d8431a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_placeholder_project(project_id, **kwargs):\n",
    "    PROJ = {}\n",
    "    PROJ['project_id'] = project_id\n",
    "\n",
    "    PROJ['project_lead_name'] = 'Morgan Wall'\n",
    "    PROJ['project_lead_email'] = 'mkwall@lbl.gov'\n",
    "    PROJ['organization'] = \"Molecular Foundry\"\n",
    "    PROJ['status'] = 'inactive'\n",
    "    PROJ['title'] = project_id\n",
    "    return PROJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0bedc3-b25a-443c-a5e4-8f276de3b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_copy = []"
   ]
=======
   "id": "35d744d7-ffc7-4c50-860c-a929c89b724b",
   "metadata": {},
   "outputs": [],
   "source": "# Check if each dataset exists in the new database\nmissing_datasets = []\nexisting_datasets = []\n\nfor dataset_id in old_dataset_ids:\n    try:\n        # Try to get the dataset from the new API\n        dataset = crux.get_dataset(dataset_id)\n        existing_datasets.append(dataset_id)\n        print(f\"✓ Dataset {dataset_id} exists in new database\")\n    except Exception as e:\n        missing_datasets.append(dataset_id)\n        print(f\"✗ Dataset {dataset_id} missing from new database: {str(e)}\")\n\nprint(f\"\\nSummary:\")\nprint(f\"Existing datasets: {len(existing_datasets)}\")\nprint(f\"Missing datasets: {len(missing_datasets)}\")\nprint(f\"Missing dataset IDs: {missing_datasets[:10]}...\")  # Show first 10"
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db9e2d9-00e9-4c5c-a72a-78f81bd56390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it does not exist -- add it\n",
<<<<<<< HEAD
    "from pycrucible.utils import run_shell\n",
    "import sys\n",
    "import json\n",
    "sys.path.append(\"/home/jupyter-mkwall/git/\")\n",
    "from crucible_utils.mf_proposal_db_utils import build_mfuser, build_mfp_project\n",
    "from crucible_utils.constants import propdb_api_url\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "errors = []\n",
    "no_json = []\n",
    "for i,dsid in enumerate(missing_ds):\n",
    "    local_json_path = f'./missing-ds-json/{dsid}.json'\n",
    "    \n",
    "    if not os.path.exists(local_json_path):\n",
    "        run_shell(f\"rclone copy mf-cloud-storage:/mf-storage-prod/{dsid}/{dsid}.json ./missing-ds-json/\")\n",
    "\n",
    "    if i%20==0:\n",
    "        print(i)\n",
    "        \n",
    "    # if it still doesn't exist make a note\n",
    "    if not os.path.exists(local_json_path):\n",
    "        no_json.append(dsid)\n",
    "        \n",
    "    else:\n",
    "        with open(local_json_path) as f:\n",
    "            D = json.load(f)\n",
    "\n",
    "        # User\n",
    "        if isinstance(D['orcid'],str) and D['orcid'] != 'XXXX-XXXX-XXXX-XXXX':\n",
    "            #print(f\"{dsid} has user {D['orcid']}\")\n",
    "            try:\n",
    "                user = crux.get_or_add_user(orcid = D['orcid'], get_user_info_function = build_mfuser, propdb_api_url = propdb_api_url)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        # Project\n",
    "        prop = D.get('proposal', None)\n",
    "        if prop is None:\n",
    "            prop = D.get('project', None)\n",
    "            print(f\"found as project for {dsid}\")\n",
    "            \n",
    "        if isinstance(prop, str) and prop not in ['', 'unknown']:\n",
    "            try:\n",
    "                proj = crux.get_or_add_project(crucible_project_id = D['proposal'], \n",
    "                                               get_project_info_function = build_mfp_project, \n",
    "                                               propdb_api_url = propdb_api_url)\n",
    "            except:\n",
    "                proj = crux.get_or_add_project(crucible_project_id = D['proposal'], \n",
    "                               get_project_info_function = build_placeholder_project, \n",
    "                               propdb_api_url = propdb_api_url)\n",
    "                \n",
    "        public_value = D.get(\"public\", False)\n",
    "\n",
    "        try:\n",
    "            # Dataset Record, Instrument, Scientific Metadata, Keywords, Access Groups\n",
    "            new_ds_record = crux.create_dataset(dataset_name = D['dataset_name'],\n",
    "                                             unique_id = D['unique_id'], \n",
    "                                             public = D.get(\"public\", False),\n",
    "                                             owner_orcid = D['orcid'],\n",
    "                                             project_id= D.get(\"proposal\", 'unknown'),\n",
    "                                             instrument_name= D['instrument_name'],\n",
    "                                             measurement = D.get('measurement', None), \n",
    "                                             session_name = D.get(\"session\", None),\n",
    "                                             creation_time = D['creation_time'],\n",
    "                                             data_format = D['data_format'], \n",
    "                                             scientific_metadata= D['metadata_dictionary'],\n",
    "                                             keywords = D['keywords'], \n",
    "                                             file_to_upload = D['file_to_upload'])\n",
    "            \n",
    "            # Associated Files\n",
    "            if isinstance(D['associated_files'], list):\n",
    "                for af in D['associated_files']:\n",
    "                    try:\n",
    "                        response = crux.add_associated_file(dsid, af['path'], af['size'], af['sha256_hash'])\n",
    "                    except:\n",
    "                        print(af)\n",
    "            elif isinstance(D['associated_files'], dict):\n",
    "                for k,v in D['associated_files'].items():\n",
    "                    try:\n",
    "                        response = crux.add_associated_file(dsid, k, v['size'], v['sha256_hash'])\n",
    "                    except:\n",
    "                        print(k,v)\n",
    "            else:\n",
    "                print(type(D['associated_files']))\n",
    "    \n",
    "            # Thumbnails\n",
    "            for tn in D['thumbnails']:\n",
    "                crux.add_thumbnail(dsid, tn['filepath'], tn['thumbnail'])\n",
    "                \n",
    "        except Exception as err:\n",
    "            errors.append({'dsid':dsid, 'error':err})\n",
    "            \n",
    "errors_copy += errors"
=======
    "'''\n",
    "pull JSON for dataset ID from cloud storage\n",
    "upload new dataset\n",
    "create any required access groups, projects, user entities, scientific metadata, thumbnails, associated files\n",
    "'''"
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "f0764bc9-fc9c-4d39-bf08-c836cb9bdb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525cb48-0583-494e-8864-db5a30021d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4fc86c-cb56-4992-9ed2-3b0d3335d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_json"
=======
   "id": "8141ac81-9731-4ef6-b21b-7b6057dff2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it does exist -- check that the scientific metadata, associated files, owner, and project also exist\n",
    "\n",
    "# if not add them"
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
<<<<<<< HEAD
}
=======
}
>>>>>>> 6171f8254c79482c76fd3807d9b6b00ed2583ea0
