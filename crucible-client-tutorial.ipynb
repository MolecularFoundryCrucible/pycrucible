{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crucible Python Client Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the Crucible Python Client to interact with the Molecular Foundry data lakehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, import the client and initialize it with your API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pycrucible import CrucibleClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the client\n",
    "api_url = os.environ.get(\"crucible_api_url\")\n",
    "api_key = os.environ.get(\"user_apikey\")  # or \"admin_apikey\" for admin access\n",
    "\n",
    "client = CrucibleClient(api_url, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Searching for Datasets\n",
    "\n",
    "Use `list_datasets()` to search for datasets with optional filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all datasets (limited to 10 results)\n",
    "datasets = client.list_datasets(limit=10)\n",
    "print(f\"Found {len(datasets)} datasets\")\n",
    "print(f\"\\nFirst dataset: {datasets[0]['dataset_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available Filters\n",
    "\n",
    "You can filter datasets using various parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by keyword\n",
    "keyword_datasets = client.list_datasets(keyword='tem', limit=5)\n",
    "print(f\"Datasets with keyword 'tem': {len(keyword_datasets)}\")\n",
    "\n",
    "# Filter by instrument\n",
    "instrument_datasets = client.list_datasets(instrument='titanx', limit=5)\n",
    "print(f\"Datasets from 'titanx' instrument: {len(instrument_datasets)}\")\n",
    "\n",
    "# Filter by owner ORCID\n",
    "owner_datasets = client.list_datasets(owner_orcid='0009-0001-9493-2006', limit=5)\n",
    "print(f\"Datasets by owner: {len(owner_datasets)}\")\n",
    "\n",
    "# Combine multiple filters\n",
    "filtered = client.list_datasets(keyword='stem', instrument='titanx', limit=5)\n",
    "print(f\"Datasets matching multiple filters: {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search datasets by sample ID\n",
    "sample_id = '0t3q9zq7enrhf0004dvevszkmm'  # Example sample ID\n",
    "sample_datasets = client.list_datasets(sample_id=sample_id)\n",
    "print(f\"Datasets for sample {sample_id}: {len(sample_datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adding Datasets\n",
    "\n",
    "There are two main ways to add datasets: from JSON metadata only, or with a file upload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: Add Dataset from JSON (metadata only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mfid  # For generating unique IDs\n",
    "\n",
    "# Create dataset with metadata only\n",
    "result = client.build_new_dataset_from_json(\n",
    "    dataset_name='My New Dataset',\n",
    "    unique_id=mfid.mfid()[0],\n",
    "    owner_orcid='0009-0001-9493-2006',\n",
    "    project_id='MFP08540',\n",
    "    instrument_name='titanx',\n",
    "    measurement='haadf',\n",
    "    public=False,\n",
    "    scientific_metadata={'voltage': '200kV', 'magnification': '50000x'},\n",
    "    keywords=['tem', 'nanoparticles']\n",
    ")\n",
    "\n",
    "dsid = result['created_record']['unique_id']\n",
    "print(f\"Created dataset: {dsid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B: Add Dataset with File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset with file upload and ingestion\n",
    "file_path = '/path/to/your/data.dm4'\n",
    "\n",
    "result = client.build_new_dataset_from_file(\n",
    "    files_to_upload=[file_path],\n",
    "    dataset_name='Dataset with File',\n",
    "    unique_id=mfid.mfid()[0],\n",
    "    owner_orcid='0009-0001-9493-2006',\n",
    "    project_id='MFP08540',\n",
    "    instrument_name='titanx',\n",
    "    measurement='stem',\n",
    "    scientific_metadata={'exposure_time': '1s', 'beam_current': '100pA'},\n",
    "    keywords=['stem', 'eels'],\n",
    "    ingestor='ImageIngestor',  # Optional: specify ingestion class\n",
    "    wait_for_ingestion_response=True\n",
    ")\n",
    "\n",
    "dsid = result['created_record']['unique_id']\n",
    "print(f\"Created dataset with file: {dsid}\")\n",
    "print(f\"Ingestion status: {result['ingestion_request']['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Updating Datasets\n",
    "\n",
    "Update existing dataset fields or scientific metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update basic dataset fields\n",
    "dsid = '04qed8jsxd3avcgk7d443rw7t4'  # Example dataset ID\n",
    "\n",
    "updated = client.update_dataset(\n",
    "    dsid,\n",
    "    dataset_name='Updated Dataset Name',\n",
    "    public=True,\n",
    "    measurement='stem-eels'\n",
    ")\n",
    "\n",
    "print(f\"Updated dataset: {updated['dataset_name']}\")\n",
    "print(f\"Now public: {updated['public']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update scientific metadata (merge with existing)\n",
    "new_metadata = {\n",
    "    'new_parameter': 'new_value',\n",
    "    'analysis_date': '2024-01-15'\n",
    "}\n",
    "\n",
    "client.update_scientific_metadata(dsid, new_metadata, overwrite=False)\n",
    "print(\"Scientific metadata updated (merged)\")\n",
    "\n",
    "# Or overwrite all scientific metadata\n",
    "complete_metadata = {\n",
    "    'voltage': '300kV',\n",
    "    'magnification': '100000x'\n",
    "}\n",
    "\n",
    "client.update_scientific_metadata(dsid, complete_metadata, overwrite=True)\n",
    "print(\"Scientific metadata replaced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add keywords to a dataset\n",
    "client.add_dataset_keyword(dsid, 'nanomaterials')\n",
    "client.add_dataset_keyword(dsid, 'characterization')\n",
    "print(\"Keywords added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Downloading Datasets\n",
    "\n",
    "Download dataset files to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (uses file_to_upload field from dataset)\n",
    "dsid = '04qed8jsxd3avcgk7d443rw7t4'\n",
    "\n",
    "client.download_dataset(dsid)\n",
    "print(f\"Dataset downloaded to: crucible-downloads/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download with custom output path\n",
    "client.download_dataset(\n",
    "    dsid,\n",
    "    file_name='data.dm4',\n",
    "    output_path='/custom/path/data.dm4'\n",
    ")\n",
    "print(\"Downloaded to custom location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Working with Samples\n",
    "\n",
    "Create samples and link them to datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a New Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new sample\n",
    "sample = client.add_sample(\n",
    "    unique_id=mfid.mfid()[0],\n",
    "    sample_name='Au Nanoparticles Batch 42',\n",
    "    description='Gold nanoparticles synthesized via citrate reduction',\n",
    "    owner_orcid='0009-0001-9493-2006',\n",
    "    creation_date='2024-01-15'\n",
    ")\n",
    "\n",
    "sample_id = sample['unique_id']\n",
    "print(f\"Created sample: {sample_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link Sample to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link an existing sample to a dataset\n",
    "dataset_id = '04qed8jsxd3avcgk7d443rw7t4'\n",
    "sample_id = '0t3q9zq7enrhf0004dvevszkmm'\n",
    "\n",
    "link = client.add_sample_to_dataset(dataset_id, sample_id)\n",
    "print(f\"Linked sample {sample_id} to dataset {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Datasets for a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all datasets associated with a sample\n",
    "sample_datasets = client.list_datasets(sample_id=sample_id)\n",
    "print(f\"Found {len(sample_datasets)} datasets for sample {sample_id}\")\n",
    "\n",
    "for ds in sample_datasets[:3]:  # Show first 3\n",
    "    print(f\"  - {ds['dataset_name']} ({ds['unique_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Sample Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sample details\n",
    "sample = client.get_sample(sample_id)\n",
    "print(f\"Sample name: {sample['sample_name']}\")\n",
    "print(f\"Description: {sample.get('description', 'N/A')}\")\n",
    "print(f\"Owner ORCID: {sample.get('owner_orcid', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full dataset information with metadata\n",
    "dataset = client.get_dataset(dsid, include_metadata=True)\n",
    "print(f\"Dataset: {dataset['dataset_name']}\")\n",
    "print(f\"Instrument: {dataset.get('instrument_name', 'N/A')}\")\n",
    "print(f\"Scientific metadata: {dataset.get('scientific_metadata', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available projects\n",
    "projects = client.list_projects(limit=5)\n",
    "for proj in projects:\n",
    "    print(f\"{proj['project_id']}: {proj.get('title', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available instruments\n",
    "instruments = client.list_instruments(limit=5)\n",
    "for inst in instruments:\n",
    "    print(f\"{inst['instrument_name']} (Location: {inst.get('location', 'N/A')})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
