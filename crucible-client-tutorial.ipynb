{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crucible Python Client Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the Crucible Python Client to interact with the Crucible Data Platform.\n",
    "<br>\n",
    "You can run ```help(client.{function_name})``` to see details about any of the client functions.\n",
    "<br>\n",
    "Replace ```{function_name}``` with the name of the function you want to see!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First, import the client and initialize it with your API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pycrucible import CrucibleClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the client\n",
    "api_url = os.environ.get(\"crucible_api_url\")\n",
    "api_key = os.environ.get(\"user_apikey\")  # or \"admin_apikey\" for admin access\n",
    "\n",
    "client = CrucibleClient(api_url, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Searching for Datasets\n",
    "\n",
    "Use `list_datasets()` to search for datasets with optional filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Found 10 datasets\n",
      "\n",
      "First dataset: 231102_195705_hyperspec_picam_mcl\n"
     ]
    }
   ],
   "source": [
    "# List all datasets (limited to 10 results)\n",
    "datasets = client.list_datasets(limit=10)\n",
    "print(f\"Found {len(datasets)} datasets\")\n",
    "print(f\"\\nFirst dataset: {datasets[0]['dataset_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Available Filters\n",
    "\n",
    "You can filter datasets using various parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by keyword\n",
    "keyword_datasets = client.list_datasets(keyword='tem', limit=5)\n",
    "print(f\"Datasets with keyword 'tem': {len(keyword_datasets)}\")\n",
    "\n",
    "# Filter by instrument\n",
    "instrument_datasets = client.list_datasets(instrument='titanx', limit=5)\n",
    "print(f\"Datasets from 'titanx' instrument: {len(instrument_datasets)}\")\n",
    "\n",
    "# Filter by owner ORCID\n",
    "owner_datasets = client.list_datasets(owner_orcid='0009-0001-9493-2006', limit=5)\n",
    "print(f\"Datasets by owner: {len(owner_datasets)}\")\n",
    "\n",
    "# Combine multiple filters\n",
    "filtered = client.list_datasets(keyword='stem', instrument='titanx', limit=5)\n",
    "print(f\"Datasets matching multiple filters: {len(filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search datasets by sample ID\n",
    "sample_id = '0t3q9zq7enrhf0004dvevszkmm'  # Example sample ID\n",
    "sample_datasets = client.list_datasets(sample_id=sample_id)\n",
    "print(f\"Datasets for sample {sample_id}: {len(sample_datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adding Datasets\n",
    "\n",
    "There are two main ways to add datasets: from JSON metadata only, or with a file upload."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option A: Add Dataset from JSON (metadata only)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import mfid  # For generating unique IDs\n",
    "\n",
    "# Create dataset with metadata only\n",
    "result = client.build_new_dataset_from_json(\n",
    "    dataset_name='TEST2 - My New Dataset',\n",
    "    unique_id=mfid.mfid()[0],\n",
    "    owner_orcid='0009-0001-9493-2006',\n",
    "    project_id='MFP08540',\n",
    "    instrument_name='titanx',\n",
    "    measurement='haadf',\n",
    "    public=False,\n",
    "    scientific_metadata={'voltage': '200kV', 'magnification': '50000x'},\n",
    "    keywords=['tem', 'nanoparticles']\n",
    ")\n",
    "\n",
    "dsid = result['created_record']['unique_id']\n",
    "print(f\"Created dataset: {dsid}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# check what it looks like in the database\n",
    "new_ds = client.get_dataset(dsid = dsid)\n",
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Data to this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option B: Add Dataset with File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method build_new_dataset_from_file in module pycrucible.pycrucible:\n",
      "\n",
      "build_new_dataset_from_file(files_to_upload: List[str], dataset_name: Optional[str] = None, unique_id: Optional[str] = None, public: bool = False, owner_orcid: Optional[str] = None, owner_user_id: Optional[int] = None, project_id: Optional[str] = None, instrument_name: Optional[str] = None, instrument_id: Optional[int] = None, measurement: Optional[str] = None, session_name: Optional[str] = None, creation_time: Optional[str] = None, data_format: Optional[str] = None, source_folder: Optional[str] = None, scientific_metadata: Optional[dict] = None, keywords: List[str] = None, get_user_info_function=None, ingestor=None, verbose=False, wait_for_ingestion_response=True, **kwargs) method of pycrucible.pycrucible.CrucibleClient instance\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client.build_new_dataset_from_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create dataset with file upload and ingestion\n",
    "file_path = './test-data/0sdazahr0nxh300075jj73j2kg_240119_144139_hyperspec_picam_mcl.h5'\n",
    "\n",
    "result = client.build_new_dataset_from_file(\n",
    "    files_to_upload=[file_path],\n",
    "    dataset_name='TEST2 - Dataset with File',\n",
    "    unique_id='0sdazahr0nxh300075jj73j2kg', # if you are using a dataset where the instrument assigned a UUID - please use that uuid\n",
    "    owner_orcid='0009-0001-9493-2006',\n",
    "    project_id='MFP08540',\n",
    "    scientific_metadata={'notes': 'this is a test dataset we keep reusing'},\n",
    "    keywords=['test'],\n",
    "    ingestor='HyperspecScopeFoundryH5Ingestor',  # Optional: specify ingestion class\n",
    "    wait_for_ingestion_response=True\n",
    ")\n",
    "\n",
    "dsid = result['created_record']['unique_id']\n",
    "print(f\"Created dataset with file: {dsid}\")\n",
    "print(f\"Ingestion status: {result['ingestion_request']['status']}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# check what it looks like in the database\n",
    "dsid = result['created_record']['unique_id']\n",
    "new_ds = client.get_dataset(dsid = dsid)\n",
    "new_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Updating Datasets\n",
    "\n",
    "Update existing dataset fields or scientific metadata."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Update basic dataset fields\n",
    "dsid = result['created_record']['unique_id']\n",
    "updated = client.update_dataset(\n",
    "    dsid,\n",
    "    dataset_name='Updated Dataset Name',\n",
    "    public=True,\n",
    "    measurement='Hyperspectral Raman'\n",
    ")\n",
    "\n",
    "print(f\"Updated dataset: {updated['dataset_name']}\")\n",
    "print(f\"Now public: {updated['public']}\")\n",
    "client.get_dataset(dsid = dsid)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Update scientific metadata (merge with existing)\n",
    "dsid = result['created_record']['unique_id']\n",
    "new_metadata = {\n",
    "    'new_parameter': 'new_value',\n",
    "    'analysis_date': '2024-01-15'\n",
    "}\n",
    "\n",
    "client.update_scientific_metadata(dsid, new_metadata, overwrite=False)\n",
    "print(\"Scientific metadata updated (merged)\")\n",
    "client.get_dataset(dsid = dsid, include_metadata = True)\n",
    "# Or overwrite all scientific metadata\n",
    "complete_metadata = {\n",
    "    'voltage': '300kV',\n",
    "    'magnification': '100000x'\n",
    "}\n",
    "\n",
    "client.update_scientific_metadata(dsid, complete_metadata, overwrite=True)\n",
    "print(\"Scientific metadata replaced\")\n",
    "client.get_dataset(dsid = dsid, include_metadata = True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Add keywords to a dataset\n",
    "client.add_dataset_keyword(dsid, 'nanomaterials')\n",
    "client.add_dataset_keyword(dsid, 'characterization')\n",
    "\n",
    "print(\"Keywords added\")\n",
    "client.get_dataset_keywords(dsid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Downloading Datasets\n",
    "\n",
    "Download dataset files to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (uses file_to_upload field from dataset)\n",
    "import time\n",
    "st = time.time()\n",
    "dsid = '0swxg30hgxtdb000wxqmapw6kr'\n",
    "\n",
    "client.download_dataset(dsid)\n",
    "end = time.time()\n",
    "print(end - st)\n",
    "print(f\"Dataset downloaded to: crucible-downloads/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download with custom output path\n",
    "dsid = '04qed8jsxd3avcgk7d443rw7t4'\n",
    "client.download_dataset(\n",
    "    dsid,\n",
    "    output_path='./experiment1_data/'\n",
    ")\n",
    "print(\"Downloaded to custom location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Working with Samples\n",
    "\n",
    "Create samples and link them to datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a New Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new sample\n",
    "sample = client.add_sample(\n",
    "    unique_id=mfid.mfid()[0],\n",
    "    sample_name='Au Nanoparticles Batch 42',\n",
    "    description='Gold nanoparticles synthesized via citrate reduction',\n",
    "    owner_orcid='0009-0001-9493-2006',\n",
    "    creation_date='2024-01-15'\n",
    ")\n",
    "\n",
    "sample_id = sample['unique_id']\n",
    "print(f\"Created sample: {sample_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link Sample to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link an existing sample to a dataset\n",
    "dataset_id = '04qed8jsxd3avcgk7d443rw7t4'\n",
    "sample_id = '0t3q9zq7enrhf0004dvevszkmm'\n",
    "\n",
    "link = client.add_sample_to_dataset(dataset_id, sample_id)\n",
    "print(f\"Linked sample {sample_id} to dataset {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Datasets for a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all datasets associated with a sample\n",
    "sample_datasets = client.list_datasets(sample_id=sample_id)\n",
    "print(f\"Found {len(sample_datasets)} datasets for sample {sample_id}\")\n",
    "\n",
    "for ds in sample_datasets[:3]:  # Show first 3\n",
    "    print(f\"  - {ds['dataset_name']} ({ds['unique_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Sample Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sample details\n",
    "sample = client.get_sample(sample_id)\n",
    "print(f\"Sample name: {sample['sample_name']}\")\n",
    "print(f\"Description: {sample.get('description', 'N/A')}\")\n",
    "print(f\"Owner ORCID: {sample.get('owner_orcid', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full dataset information with metadata\n",
    "dataset = client.get_dataset(dsid, include_metadata=True)\n",
    "print(f\"Dataset: {dataset['dataset_name']}\")\n",
    "print(f\"Instrument: {dataset.get('instrument_name', 'N/A')}\")\n",
    "print(f\"Scientific metadata: {dataset.get('scientific_metadata', {})}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available projects\n",
    "projects = client.list_projects(limit=5)\n",
    "for proj in projects:\n",
    "    print(f\"{proj['project_id']}: {proj.get('title', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available instruments\n",
    "instruments = client.list_instruments(limit=5)\n",
    "for inst in instruments:\n",
    "    print(f\"{inst['instrument_name']} (Location: {inst.get('location', 'N/A')})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
